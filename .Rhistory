install.packages("devtools")
library(devtools)
install.packages("devtools")
install.packages("devtools")
library(devtools)
find_rtools()
install.packages("KernSmooth")
library(KernSmooth)
getwd()
dir
dir()
getwd()
setwd("~/CourseraCode")
?rnorm
getwd()
x
x <- 1
x
x <- 1:20
x
x <- 1:3
y <- 10:12
cbind(x,y)
x <- 4L
x
class(x)
x <- c(4, TRUE)
class(x)
x
a <- c(4, TRUE)
class(a)
a
x <- c(1,3,5)
y <- c(3,2,10)
cbind(x,y)
x <- 1:4
y<-2:3
x + y
z<-x + y
class(z)
class(x+y)
x <- c(3, 5, 1, 10, 12, 6)
x
x[x<6] <- 0
x
read.csv("hw1_data.csv")
DataA = read.csv("hw1_data.csv")
getwd()
read.csv("hw1_data.csv")
DataA = read.csv("hw1_data.csv")
DataA
DataA
names(DataA)
readLines(DataA,2)
source('~/.active-rstudio-document', echo=TRUE)
readLines(DataA)
Readlines(DataB,2)
DataC <-Readlines(DataB,2)
DataC <-readLines(DataB,2)
DataB <- file("hw1_data.csv")
DataC <-readLines(DataB,2)
DataC
attr(DataA)
attributes(DataA)
dim(DataA)
DataA[152:153]
DataA[c(152:153)]
q <- DataA[c(152:153)]
q <- DataA[c(152,153)]
q
DataA = read.csv("hw1_data.csv")
DataA
q <- DataA[c(152,153),]
q
q <- DataA[c(47),]
q
q <- DataA[c(47),1]
q
q <- DataA[NA,1]
q
q <- DataA[1]
q
is.NA(q)
is.na(q)
r <- is.na(q)
q[r]
r <- is.nan(q)
r <- is.na(q)
q[r]
q[!r]
s <- q[!r]
s
mean(s)
names(DataA)
DataA[[1]][[1]]
DataA[[2]][[1]]
DataA[["Ozone"]]
DataA
DataA[["Month"==5]]
DataA[["Month" = 5]]
DataA[["Month" > 5]]
subset(DataA, Month >5 & Day > 10)
a <- subset(DataA, Ozone >31 & Temp > 90)
a
b <- a["Solar.R"]
b
mean(b)
b <- a[["Solar.R"]]
b
mean(b)
a <- subset(DataA, Month == 6)
a
mean(a[["Temp"]])
a <- subset(DataA, Month == 6)
a
b <- a[["Ozone"]]
b
max(b)
c <- is.na(b)
d < b[c]
d <- b[c]
d
d <- b[!c]
d
max[d]
d <- b[[!c]]
d
max[d]
max(d)
a <- subset(DataA, Month == 5)
a
b <- a[["Ozone"]]
c <- is.na(b)
d <- b[[!c]]
d
max(d)
a <- subset(DataA, Month == 5)
a
b <- a[["Ozone"]]
c <- is.na(b)
d <- b[[!c]]
d <- b[!c]
d
source('~/.active-rstudio-document', echo=TRUE)
max(d)
x <- list(2, "a", "b", TRUE)
x[[2]]
y <- x[[2]]
class(y)
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
f
?rnorm
?if
?return()
?return()
?if()
getwd
source("pollutantmean.R")
pollutantmean("specdata", "sulfate", 1:10)
source("pollutantmean.R")
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
source("pollutantmean.R")
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "nitrate", 23)
##Part2
source("complete.R")
complete("specdata", 1)
source("complete.R")
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
source("complete.R")
complete("specdata", 1)
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 30:25)
complete("specdata", 3)
source("corr.R")
source("complete.R")
cr <- corr("specdata", 150)
head(cr)
summary(cr)
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata", 5000)
summary(cr)
length(cr)
cr <- corr("specdata")
summary(cr)
length(cr)
source("corr.R")
source("complete.R")
cr <- corr("specdata", 150)
head(cr)
complete_cases <- complete_filenames(directory)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
2
submit()
submit()
submit()
submit()
submit()
submit()
# getmonitor.R
getmonitor <- function(id, directory, summarize = FALSE) {
## 'id' is a vector of length 1 indicating the monitor ID
## number. The user can specify 'id' as either an integer, a
## character, or a numeric.
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'summarize' is a logical indicating whether a summary of
## the data should be printed to the console; the default is
## FALSE
id3 <- formatC(id, width=3, flag="0")
filename <- paste(directory, '\\', id3, '.csv', sep='')
data <- read.csv(file=filename)
if(summarize) {
print(summary(data))
}
data
}
corr <- function(directory, threshold = 0) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'threshold' is a numeric vector of length 1 indicating the
## number of completely observed observations (on all
## variables) required to compute the correlation between
## nitrate and sulfate; the default is 0
## Return a numeric vector of correlations
comp.data <- complete(directory)
k <- subset(comp.data, comp.data$nobs > threshold)
obj.id <-c(k[,1])
L<-length(obj.id)
j<- vector("numeric", length = 0)
for (i in obj.id) {
raw.data <- getmonitor(i, directory)
a <- na.omit(raw.data)
b <- cor(a$sulfate, a$nitrate)
j <- append(j, b, after= length(j))
}
c(j)
j
}
submit()
submit()
submit()
source('~/CourseraCode/best.R', echo=TRUE)
source('~/CourseraCode/rankall.R', echo=TRUE)
source('~/CourseraCode/rankhospital.R', echo=TRUE)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
2
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
agricultureLogical <- df$ACR==3 & df$AGS ==6
ans <- which(agricultureLogical)[1:3]
ans
library('jpeg')
img <- readJPEG("getdata-jeff.jpg", native = TRUE)
ans <- quantile(img, probs=c(0.3,0.8))
ans
gdprankings <- read.csv('getdata-data-GDP.csv', skip=4, stringsAsFactors = FALSE)
# Remove empty cols and ammend colnames
gdprankings[,3] <- gdprankings[,6] <- gdprankings[,7] <- gdprankings[,8] <- gdprankings[,9] <- gdprankings[,10]  <- NULL
colnames(gdprankings) <- c("abbreviation", "ranking", "economy", "gdp")
gdprankings <- gdprankings[gdprankings$abbreviation != "", ] # Remove entries w/ no abbreviation
gdprankings <- gdprankings[1:190,] ## Remove regions - just keep countries
gdprankings[,2] <- as.numeric(gdprankings[,2])
gdprankings[,4] <- gsub(",", "", gdprankings[,4]) # Remove "," to allow coercion
gdprankings[,4] <- as.integer(gdprankings[,4])
gdprankings <- gdprankings[order(gdp[,2]), ] ## Order by "gdp" descending
gdprankings[1:13,]
gdprankings <- read.csv('getdata-data-GDP.csv', skip=4, stringsAsFactors = FALSE)
gdprankings[,3] <- gdprankings[,6] <- gdprankings[,7] <- gdprankings[,8] <- gdprankings[,9] <- gdprankings[,10]  <- NULL
gdprankings
colnames(gdprankings) <- c("abbreviation", "ranking", "economy", "gdp")
gdprankings
gdprankings <- gdprankings[gdprankings$abbreviation != "", ] # Remove entries w/ no abbreviation
gdprankings
gdprankings <- read.csv('getdata-data-GDP.csv', skip=4, stringsAsFactors = FALSE)
gdprankings[,3] <- gdprankings[,6] <- gdprankings[,7] <- gdprankings[,8] <- gdprankings[,9] <- gdprankings[,10]  <- NULL
colnames(gdprankings) <- c("abbreviation", "ranking", "economy", "gdp")
gdprankings <- gdprankings[gdprankings$abbreviation != "", ] # Remove entries w/ no abbreviation
gdprankings <- read.csv('getdata-data-GDP.csv', skip=4, stringsAsFactors = FALSE)
# Remove empty cols and ammend colnames
gdprankings[,3] <- gdprankings[,6] <- gdprankings[,7] <- gdprankings[,8] <- gdprankings[,9] <- gdprankings[,10]  <- NULL
colnames(gdprankings) <- c("abbreviation", "ranking", "economy", "gdp")
gdprankings <- gdprankings[gdprankings$abbreviation != "", ] # Remove entries w/ no abbreviation
gdprankings <- gdprankings[1:190,] ## Remove regions - just keep countries
gdprankings[,2] <- as.numeric(gdprankings[,2])
gdprankings
gdprankings[,4] <- gsub(",", "", gdprankings[,4]) # Remove "," to allow coercion
gdprankings
gdprankings[,4] <- as.integer(gdprankings[,4])
gdprankings
gdprankings <- gdprankings[order(gdp[,2]), ] ## Order by "gdp" descending
edstats <- read.csv('getdata-data-EDSTATS_Country.csv', stringsAsFactors = FALSE)
mergeddata <- merge(gdprankings, edstats, by.x = "abbreviation", by.y = "CountryCode", all = FALSE)
res1 <- mean(mergeddata[mergeddata$Income.Group=="High income: OECD",]$ranking)
res2 <- mean(mergeddata[mergeddata$Income.Group=="High income: nonOECD",]$ranking)
ans <- c(res1, res2)
ans
quantiles <- quantile(x = mergeddata$gdp, probs=c(0.2,0.4,0.6,0.8,1))
topQuantileRange <- quantiles[4]
data <- mergeddata[mergeddata$Income.Group=="Lower middle income" & mergeddata$gdp > topQuantileRange,]
ans <- nrow(data)
ans
source('~/CourseraCode/GettingnCleaningData_DigitalDreamr/run_analysis.R', echo=TRUE)
library("dplyr", lib.loc="~/R/win-library/3.1")
source('~/CourseraCode/GettingnCleaningData_DigitalDreamr/run_analysis.R', echo=TRUE)
install.packages("plyr")
library("plyr", lib.loc="~/R/win-library/3.1")
source('~/CourseraCode/GettingnCleaningData_DigitalDreamr/run_analysis.R', echo=TRUE)
dir
getdir()
dir()
dir()
setwd("~/CourseraCode/GettingnCleaningData_DigitalDreamr")
source('~/.active-rstudio-document', echo=TRUE)
CombinedMeansData <- ddply(CombinedData, .(Subject, Activity), numcolwise(mean))
names(CombinedMeansData)[-c(1,2)] <- paste0("Mean_of_", names(CombinedMeansData)[-c(1,2)])
CombinedMeansData <- ddply(CombinedData, .(Subject, Activity), numcolwise(mean))
CombinedMeansData <- ddply(CombinedData, .(Subject, Activity), numcolwise(mean))
### Coursera - Getting & Cleaning Data
### My Assignment Submission
### DigitalDreamr
### STEP 0: Load the required packages
library(plyr)
### STEP 1: Merges the training and the test sets to create one data set
# Reading the Training dataset
TrainSubject <- read.table("./UCI HAR Dataset/train/subject_train.txt")
TrainX <- read.table("./UCI HAR Dataset/train/X_train.txt")
TrainY <- read.table("./UCI HAR Dataset/train/y_train.txt")
TrainData <- cbind(TrainSubject, TrainY, TrainX)
# Reading the Test dataset
TestSubject <- read.table("./UCI HAR Dataset/test/subject_test.txt")
TestX <- read.table("./UCI HAR Dataset/test/X_test.txt")
TestY <- read.table("./UCI HAR Dataset/test/y_test.txt")
TestData <- cbind(TestSubject, TestY, TestX)
# Combine both Training and Test datasets
CombinedData <- rbind(TrainData, TestData)
## Rename the column names.
# Get the feature names using for X_train.txt and X_test.txt.
# The feature names are in the second column.
FeatureNames <- read.table("./UCI HAR Dataset/features.txt", stringsAsFactors = FALSE)[, 2]
# Rename the first column to be "Subject", followed by FeatureNames, and the last as the "Activity"
names(CombinedData) <- c("Subject", "Activity", FeatureNames)
### STEP 2: Extracts only the measurements on the mean and standard deviation for each measurement.
# Get the feature names with "mean" and "std"
MeanStdFeatureNames <- grep("(mean|std)\\(\\)", names(CombinedData))
# Keep the first column "Subject" and second column "Activity" and the columns with "mean" and "std".
CombinedData <- CombinedData[, c(1, 2, MeanStdFeatureNames)]
### STEP 3: Uses descriptive activity names to name the activities in the data set
ActivityNames <- read.table("UCI HAR Dataset/activity_labels.txt")
CombinedData$Activity <- factor(CombinedData$Activity, labels=ActivityNames[, 2])
# Change t to Time, f to Frequency, mean() to Mean and std() to StdDev
# Remove extra dashes and BodyBody naming error from original feature names
names(CombinedData) <- gsub("^t", "Time", names(CombinedData))
names(CombinedData) <- gsub("^f", "Frequency", names(CombinedData))
names(CombinedData) <- gsub("-mean\\(\\)", "Mean", names(CombinedData))
names(CombinedData) <- gsub("-std\\(\\)", "StdDev", names(CombinedData))
names(CombinedData) <- gsub("-", "", names(CombinedData))
names(CombinedData) <- gsub("BodyBody", "Body", names(CombinedData))
### STEP 5: Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
CombinedMeansData <- ddply(CombinedData, .(Subject, Activity), numcolwise(mean))
library("dplyr", lib.loc="~/R/win-library/3.1")
CombinedMeansData <- ddply(CombinedData, .(Subject, Activity), numcolwise(mean))
install.packages("Rcpp")
